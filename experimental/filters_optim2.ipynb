{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sig\n",
    "from scipy.stats import linregress\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import scipy.optimize as opt\n",
    "import altair as alt\n",
    "import flammkuchen as fl\n",
    "from ray import tune\n",
    "from ray.tune import ProgressReporter, JupyterNotebookReporter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler, PopulationBasedTraining\n",
    "\n",
    "import sys,os,os.path\n",
    "sys.path.append(os.path.expanduser('../src'))\n",
    "\n",
    "from spinorama.filter_iir import Biquad\n",
    "from spinorama.filter_peq import peq_build, peq_print\n",
    "from spinorama.load import graph_melt\n",
    "from spinorama.load_rewseq import parse_eq_iir_rews\n",
    "from spinorama.graph import graph_spinorama, graph_freq, graph_regression_graph, graph_regression\n",
    "from spinorama.compute_scores import scores, nbd\n",
    "from spinorama.filter_scores import scores_apply_filter, scores_print, scores_loss\n",
    "\n",
    "logger = logging.getLogger('spinorama')\n",
    "fh = logging.FileHandler('debug_optim.log')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_speakers = fl.load('../cache.parse_all_speakers.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norm \n",
    "def lw_loss1(local_target, peq):\n",
    "    return np.linalg.norm(local_target+peq_build(freq, peq), 2)\n",
    "\n",
    "\n",
    "# sum of L2 norms if we have multiple targets\n",
    "def lw_loss2(local_target, peq, iterations):\n",
    "    return np.sum([lw_loss1(local_target[i], peq) for i in range(0, len(local_target))])\n",
    "\n",
    "\n",
    "# pref score \n",
    "def pref_loss(local_target, peq, iterations):\n",
    "    _, _, score = scores_apply_filter(df_speaker, peq)\n",
    "    return -score['pref_score']\n",
    "\n",
    "\n",
    "# make LW as close as target as possible and SP flat\n",
    "def flat_loss(local_target, peq, iterations):\n",
    "    # want lw as close as possible from targeto\n",
    "    lw = lw_loss1(local_target[0], peq)\n",
    "    # lw = nbd(local_target[0]+peq_build(freq, peq))\n",
    "    # want sound power to be flat but not necessary aligned with target\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(np.log10(freq), local_target[1])\n",
    "    sp = 1-r_value**2\n",
    "    return lw+sp\n",
    "\n",
    "\n",
    "def swap_loss(local_target, peq, iteration):\n",
    "    if len(local_target)==0 or iteration < 10:\n",
    "        return lw_loss2([local_target[0]], peq)\n",
    "    else:\n",
    "        return lw_loss2([local_target[1]], peq)\n",
    "\n",
    "\n",
    "def alternate_loss(local_target, peq, iteration):\n",
    "    if len(local_target)==0 or iteration % 2 == 0:\n",
    "        return lw_loss2([local_target[0]], peq)\n",
    "    else:\n",
    "        return lw_loss2([local_target[1]], peq)\n",
    "    \n",
    "    \n",
    "# compute pref scrore\n",
    "def score_loss(df_spin, peq):\n",
    "    \"\"\"Compute the preference score for speaker\n",
    "    \n",
    "    local_target: unsued\n",
    "    peq: evaluated peq\n",
    "    \n",
    "    return minus score (we want to maximise the score)\n",
    "    \"\"\"\n",
    "    _, _, score = scores_apply_filter(df_spin, peq)\n",
    "    return -score['pref_score']\n",
    "\n",
    "#def lw_loss_r2(local_target, peq):\n",
    "#   _, _, r_value, _, _ = linregress(np.log(freq), local_target+peq_build(freq, peq))\n",
    "#   return -r_value**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of speaker\n",
    "# speaker_name = 'KEF LS50'\n",
    "speaker_name = 'KRK Systems Classic 5'\n",
    "# speaker_name = 'Genelec 8341A'\n",
    "# speaker_name = 'Verdant Audio Bambusa MG 1'\n",
    "# speaker_name = 'Genelec 8030C'\n",
    "# all graphs for this speaker\n",
    "df_speaker = df_all_speakers[speaker_name]['ASR']['asr']\n",
    "# print(df_speaker.keys())\n",
    "# original_mean = df_speaker['CEA2034_original_mean']\n",
    "# read EQ for this speaker\n",
    "my_fs = 48000\n",
    "my_freq_reg_min = 300\n",
    "my_freq_mean_min = 100\n",
    "my_freq_mean_max = 300\n",
    "manual_peq = parse_eq_iir_rews('../datas/eq/{}/iir.txt'.format(speaker_name), my_fs)\n",
    "# peq_print(manual_peq)\n",
    "# curve to optimise for\n",
    "# curve_name = 'On Axis'\n",
    "curve_name = ['Listening Window', 'Sound Power']\n",
    "# curve_name = ['Listening Window', 'Early Reflections']\n",
    "# curve_name = ['Early Reflections', 'Listening Window']\n",
    "# curve_name = ['Sound Power', 'Listening Window']\n",
    "# curve_name = ['On Axis', 'Sound Power']\n",
    "# curve_name = ['Listening Window']\n",
    "# curve_name = ['Estimated In-Room Response']\n",
    "# curve_name = ['Early Reflections']\n",
    "# curve_name = ['Sound Power']\n",
    "my_number_curves = len(curve_name)\n",
    "\n",
    "\n",
    "def getFreq(df_speaker_data):\n",
    "    # extract LW\n",
    "    columns = {'Freq'}.union(curve_name)\n",
    "    df = df_speaker_data['CEA2034_unmelted'].loc[:, columns]\n",
    "    # selector\n",
    "    selector = df['Freq']>my_freq_reg_min\n",
    "    # freq\n",
    "    freq = df.loc[selector, 'Freq'].values\n",
    "    local_target = []\n",
    "    for i in range(0, my_number_curves):\n",
    "        local_target.append(df.loc[selector, curve_name[i]].values)\n",
    "    return df, freq, local_target\n",
    "\n",
    "\n",
    "def getCurve(df, freq, current_curve_name):\n",
    "    selector = ((df['Freq']>my_freq_mean_min) & (df['Freq']<=my_freq_mean_max))\n",
    "    # freq\n",
    "    current_curve = df.loc[df['Freq']>my_freq_reg_min, current_curve_name].values\n",
    "    # print(len(freq), len(current_curve))\n",
    "    # compute linear reg on lw\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(np.log10(freq), current_curve)\n",
    "    # normalise to have a flat target (primarly for bright speakers)\n",
    "    if current_curve_name == 'On Axis':\n",
    "        slope = 0\n",
    "        intercept = current_curve[0]\n",
    "    elif current_curve_name == 'Listening Window':\n",
    "        # slighlithy downward\n",
    "        slope = -2/math.log(20000)\n",
    "        intercept = current_curve[0]\n",
    "    elif current_curve_name == 'Early Reflections':\n",
    "        slope = -5/math.log(20000)\n",
    "        intercept = current_curve[0]\n",
    "    elif current_curve_name == 'Sound Power':\n",
    "        slope = -8/math.log(20000)\n",
    "        intercept = current_curve[0]\n",
    "    target_interp = [(slope*math.log10(freq[i])+intercept) for i in range(0, len(freq))]\n",
    "    print('Slope {} Intercept {} R {} P {} err {}'.format(slope, intercept, r_value, p_value, std_err))\n",
    "    return target_interp\n",
    "\n",
    "\n",
    "# compute linear reg on lw filtered\n",
    "df, freq, target = getFreq(df_all_speakers[speaker_name]['ASR']['asr'])\n",
    "target_interp = []\n",
    "for i in range(0, my_number_curves):\n",
    "    target_interp.append(getCurve(df, freq, curve_name[i]))\n",
    "\n",
    "#lw_interp_last = lw_interp[-1]-np.mean(lw_interp)\n",
    "#if lw_interp[-1]-np.mean(lw_interp)>0.3:\n",
    "#    print('Warning: bright target {}dB at {} Hz'.format(lw_interp_last, freq[-1]))\n",
    "\n",
    "df_eq, freq_eq, lw_eq = getFreq(df_all_speakers[speaker_name]['ASR']['asr_eq'])\n",
    "lw_eq_interp = []\n",
    "lw_target = []\n",
    "for i in range(0, my_number_curves):\n",
    "    lw_eq_interp.append(getCurve(df_eq, freq_eq, curve_name[i]))\n",
    "    lw_target.append(lw_eq[i]-lw_eq_interp[i])\n",
    "\n",
    "print('manual eq loss: {}'.format(lw_loss(lw_target, [])))\n",
    "\n",
    "target_init = target[0][0]\n",
    "df_init_curve = pd.DataFrame({'Freq': freq,\n",
    "            'curve0': target[0]-target_init,\n",
    "            'curve0 interp': target_interp[0]-target_init,\n",
    "            'manual0': lw_eq[0]-lw_eq[0][0]-5,\n",
    "            'manual0 interp': lw_eq_interp[0]-lw_eq[0][0]-5,\n",
    "        })\n",
    "for i in range(1, len(curve_name)):\n",
    "      df_init_curve['curve{}'.format(i)] = target[i]-target[i][0]-(5+i*10)\n",
    "      df_init_curve['curve{} interp'.format(i)] = target_interp[i]-target_interp[i][0]-(5+i*10)\n",
    "      df_init_curve['manual{}'.format(i)] = lw_eq[i]-lw_eq[i][0]-((i+1)*10)\n",
    "      df_init_curve['manual{} interp'.format(i)] = lw_eq_interp[i]-lw_eq_interp[i][0]-((i+1)*10)\n",
    "      \n",
    "alt.Chart(graph_melt(df_init_curve)\n",
    ").mark_line(\n",
    "    size=3\n",
    ").encode(\n",
    "    alt.X('Freq:Q', title='Freq (Hz)', scale=alt.Scale(type='log', nice=False, domain=[my_freq_reg_min, 20000])),\n",
    "    alt.Y('dB:Q', title='Sound Pressure (dB)', scale=alt.Scale(zero=False, domain=[-40, 5])),\n",
    "    alt.Color('Measurements', type='nominal', sort=None),\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel('INFO')\n",
    "smoke_test = False\n",
    "\n",
    "MAX_NUMBER_PEQ   = 20\n",
    "MAX_STEPS_FREQ   = 5\n",
    "MAX_STEPS_DBGAIN = 5\n",
    "MAX_STEPS_Q      = 5\n",
    "MIN_DBGAIN       = 0.5\n",
    "MAX_DBGAIN       = 12\n",
    "MIN_Q            = 0.5\n",
    "MAX_Q            = 12\n",
    "\n",
    "if smoke_test:\n",
    "    MAX_NUMBER_PEQ   = 3\n",
    "    MAX_STEPS_FREQ   = 3\n",
    "    MAX_STEPS_DBGAIN = 3\n",
    "    MAX_STEPS_Q      = 3\n",
    "\n",
    "# main peq that we want to find    \n",
    "auto_peq = []\n",
    "# current target is delta between curve and a line\n",
    "auto_target = []\n",
    "for i in range(0, my_number_curves):\n",
    "    auto_target.append(target[i]-target_interp[i])\n",
    "\n",
    "fixed_freq = set()\n",
    "best_loss = lw_loss(auto_target, auto_peq)\n",
    "\n",
    "\n",
    "logger.info('OPTIM {} START #PEQ {} Freq #{} Gain #{} +/-[{}, {}] Q #{} [{}, {}] Initial loss {}'.format(\n",
    "    curve_name,\n",
    "    MAX_NUMBER_PEQ, \n",
    "    MAX_STEPS_FREQ,\n",
    "    MAX_STEPS_DBGAIN, MIN_DBGAIN, MAX_DBGAIN, \n",
    "    MAX_STEPS_Q, MIN_Q, MAX_Q, \n",
    "    best_loss))\n",
    "\n",
    "\n",
    "def find_largest_area(freq, curve):\n",
    "    \n",
    "    def largest_area(positive_curve):\n",
    "        found_peaks, _ = sig.find_peaks(positive_curve, distance=10)\n",
    "        if len(found_peaks)==0:\n",
    "            return None, None\n",
    "        # print('found peaks at {}'.format(found_peaks))\n",
    "        found_widths = sig.peak_widths(positive_curve, found_peaks, rel_height=0.1)[0]\n",
    "        # print('computed width at {}'.format(found_widths))\n",
    "        areas = [(i, positive_curve[found_peaks[i]]*found_widths[i]) for i in range(0, len(found_peaks))]\n",
    "        # print('areas {}'.format(areas))\n",
    "        sorted_areas = sorted(areas, key=lambda a: -a[1])\n",
    "        # rint('sorted {}'.format(sorted_areas))\n",
    "        ipeaks, area = sorted_areas[0]\n",
    "        return found_peaks[ipeaks], area\n",
    "        \n",
    "    plus_curve = np.clip(curve, a_min=0, a_max=None)\n",
    "    plus_index, plus_areas = largest_area(plus_curve)\n",
    "    minus_curve = -np.clip(curve, a_min=None, a_max=0)\n",
    "    minus_index, minus_areas = largest_area(minus_curve)\n",
    "    \n",
    "    if minus_areas is None:\n",
    "        return +1, plus_index, freq[plus_index]\n",
    "    \n",
    "    if plus_areas is None:\n",
    "        return -1, minus_index, freq[minus_index]\n",
    "\n",
    "    if minus_areas > plus_areas:\n",
    "        return -1, minus_index, freq[minus_index]\n",
    "    else:\n",
    "        return +1, plus_index, freq[plus_index]\n",
    "\n",
    "    \n",
    "def propose_range_freq(freq, local_target):\n",
    "    sign, indice, init_freq = find_largest_area(freq, local_target)\n",
    "    elastic = 0.8\n",
    "    init_freq_min = max(init_freq*elastic, 20)\n",
    "    init_freq_max = min(init_freq/elastic, 20000)\n",
    "    init_freq_range = np.linspace(init_freq_min,  init_freq_max, MAX_STEPS_FREQ).tolist()\n",
    "    if MAX_STEPS_FREQ == 1:\n",
    "        init_freq_range = [init_freq]\n",
    "    init_freq_range = np.linspace(init_freq_min,  init_freq_max, MAX_STEPS_FREQ).tolist()\n",
    "    logger.debug('freq min {}Hz peak {}Hz max {}Hz'.format(init_freq_min, init_freq, init_freq_max))\n",
    "    return sign, init_freq, init_freq_range\n",
    "\n",
    "\n",
    "def propose_range_dbGain(freq, local_target, sign, init_freq):\n",
    "    spline = InterpolatedUnivariateSpline(np.log10(freq), local_target, k=1)\n",
    "    init_dbGain = abs(spline(np.log10(init_freq)))\n",
    "    init_dbGain_min = max(init_dbGain/5, MIN_DBGAIN)\n",
    "    init_dbGain_max = min(init_dbGain*5, MAX_DBGAIN)\n",
    "    init_dbGain_range = ()\n",
    "    if sign<0:\n",
    "        init_dbGain_range = np.linspace(init_dbGain_min, init_dbGain_max, MAX_STEPS_DBGAIN).tolist()\n",
    "    else:\n",
    "        init_dbGain_range = np.linspace(-init_dbGain_max, -init_dbGain_min, MAX_STEPS_DBGAIN).tolist()\n",
    "    logger.debug('gain min {}dB peak {}dB max {}dB'.format(init_dbGain_min, init_dbGain, init_dbGain_max))\n",
    "    return init_dbGain_range\n",
    "\n",
    "\n",
    "def propose_range_Q():\n",
    "    return np.concatenate((np.linspace(MIN_Q, 1, MAX_STEPS_Q), np.linspace(1+MIN_Q, MAX_Q, MAX_STEPS_Q)), axis=0).tolist()\n",
    "\n",
    "\n",
    "def propose_range_biquad():\n",
    "    return [Biquad.PEAK] #, Biquad.NOTCH] #, Biquad.LOWPASS, Biquad.HIGHPASS, Biquad.BANDPASS, Biquad.LOWSHELF, Biquad.HIGHSHELF]\n",
    "\n",
    "\n",
    "def find_best_biquad_raytune(auto_target, \n",
    "                             freq_range, Q_range, dbGain_range, biquad_range):\n",
    "\n",
    "    def lw_optimizer(config, checkpoint_dir = None):\n",
    "        peq = [(1.0, Biquad(config['1_type'], config['1_freq'], 48000, config['1_Q'], config['1_dbGain']))]\n",
    "        intermediate_score = lw_loss(auto_target, peq)\n",
    "        logger.debug('lw_optim: {} {}'.format(intermediate_score, peq_print(peq)))\n",
    "        tune.report(mean_loss=intermediate_score)\n",
    "\n",
    "    lw_analysis = tune.run(\n",
    "        lw_optimizer,\n",
    "        config={\n",
    "            \"1_freq\": tune.grid_search(freq_range),\n",
    "            \"1_Q\": tune.grid_search(Q_range),\n",
    "            \"1_dbGain\": tune.grid_search(dbGain_range),\n",
    "            \"1_type\": tune.grid_search(biquad_range),\n",
    "        },\n",
    "        progress_reporter=JupyterNotebookReporter(\n",
    "            overwrite=True, \n",
    "            max_progress_rows=5, \n",
    "            max_report_frequency=30, \n",
    "            print_intermediate_tables=False\n",
    "        ),\n",
    "        resources_per_trial={\"cpu\": 1},\n",
    "        metric='mean_loss',\n",
    "        mode='max')\n",
    "    \n",
    "    best = lw_analysis.get_best_trial(metric='mean_loss', mode='min').last_result\n",
    "    logger.debug('best {}'.format(best))\n",
    "    best_type   = best['config']['1_type']\n",
    "    best_dbGain = best['config']['1_dbGain']\n",
    "    best_freq   = best['config']['1_freq']\n",
    "    best_Q      = best['config']['1_Q']\n",
    "    best_loss   = best['mean_loss']\n",
    "    \n",
    "    return True, best_type, best_freq, best_Q, best_dbGain, best_loss\n",
    "\n",
    "\n",
    "def find_best_biquad_shgo(auto_target, \n",
    "                          freq_range, Q_range, dbGain_range, biquad_range, count):\n",
    "    \n",
    "    bT = 3\n",
    "\n",
    "    def opt_peq(x):\n",
    "        peq = [(1.0, Biquad(bT, x[0], 48000, x[1], x[2]))]\n",
    "        return swap_loss(auto_target, peq, count)\n",
    "                        \n",
    "    bounds = [(freq_range[0], freq_range[-1]), \n",
    "              (Q_range[0], Q_range[-1]), \n",
    "              (dbGain_range[0], dbGain_range[-1])]\n",
    "    \n",
    "    logger.debug('Optim (shgo): range is [{}, {}], [{}, {}], [{}, {}]'.format(\n",
    "        bounds[0][0], bounds[0][1], bounds[1][0], bounds[1][1], bounds[2][0], bounds[2][1]))\n",
    "    res = opt.shgo(opt_peq, bounds)\n",
    "    logger.debug('          shgo optim loss {:2.2f} in {} iter at F {:.0f} Hz Q {:2.2f}'.format(\n",
    "        res.fun, res.nfev, res.x[0], res.x[1], res.x[2]))\n",
    "    return True, bT, res.x[0], res.x[1], res.x[2], res.fun\n",
    "\n",
    "\n",
    "def find_best_biquad_differential_evolution(auto_target, freq_range, Q_range, dbGain_range, biquad_range, count):\n",
    "    \n",
    "    bT = 3\n",
    "\n",
    "    def opt_peq(x):\n",
    "        peq = [(1.0, Biquad(bT, x[0], 48000, x[1], x[2]))]\n",
    "        return flat_loss(auto_target, peq, count)\n",
    "                        \n",
    "    bounds = [(freq_range[0], freq_range[-1]), \n",
    "              (Q_range[0], Q_range[-1]), \n",
    "              (dbGain_range[0], dbGain_range[-1])]\n",
    "    \n",
    "    logger.debug('Optim (shgo): range is [{}, {}], [{}, {}], [{}, {}]'.format(\n",
    "        bounds[0][0], bounds[0][1], bounds[1][0], bounds[1][1], bounds[2][0], bounds[2][1]))\n",
    "    # can use differential_evolution basinhoppin dual_annealing\n",
    "    res = opt.dual_annealing(\n",
    "        opt_peq, \n",
    "        bounds, \n",
    "        #disp=True, \n",
    "        #tol=0.01, # increasing precision doesn't help\n",
    "    )\n",
    "    logger.debug('          shgo optim loss {:2.2f} in {} iter at F {:.0f} Hz Q {:2.2f}'.format(\n",
    "        res.fun, res.nfev, res.x[0], res.x[1], res.x[2]))\n",
    "    return True, bT, res.x[0], res.x[1], res.x[2], res.fun\n",
    "\n",
    "\n",
    "def find_best_biquad_differential_evolution2(auto_target, freq_range, Q_range, dbGain_range, biquad_range):\n",
    "    \n",
    "    def opt_peq(x):\n",
    "        biquad_freq = x[0]\n",
    "        biquad_Q = x[1]\n",
    "        biquad_dbGain = x[2]\n",
    "        biquad_type = int(x[3])\n",
    "        peq = [(1.0, Biquad(biquad_type, biquad_freq, 48000, biquad_Q, biquad_dbGain))]\n",
    "        return lw_loss(auto_target, peq)\n",
    "                        \n",
    "    bounds = [(freq_range[0], freq_range[-1]), \n",
    "              (Q_range[0], Q_range[-1]), \n",
    "              (dbGain_range[0], dbGain_range[-1]),\n",
    "              (0, 7)]\n",
    "    \n",
    "    logger.debug('Optim (shgo): range is [{}, {}], [{}, {}], [{}, {}]'.format(\n",
    "        bounds[0][0], bounds[0][1], bounds[1][0], bounds[1][1], bounds[2][0], bounds[2][1]))\n",
    "    res = opt.differential_evolution(opt_peq, \n",
    "                                     bounds, \n",
    "                                     #disp=True, \n",
    "                                     # tol=0.01, # increasing precision doesn't help\n",
    "                                     # popsize=10\n",
    "                                    )\n",
    "    logger.debug('          shgo optim loss {:2.2f} in {} iter at F {:.0f} Hz Q {:2.2f}'.format(\n",
    "        res.fun, res.nfev, res.x[0], res.x[1], res.x[2]))\n",
    "    return True, int(res.x[3]), res.x[0], res.x[1], res.x[2], res.fun\n",
    "\n",
    "    \n",
    "    \n",
    "for optim_iter in range(0, MAX_NUMBER_PEQ):\n",
    "    \n",
    "    # target curve is currently a line between my_freq_reg_min Hz and 20kHz\n",
    "    # we are optimizing above my_freq_reg_min hz on anechoic data\n",
    "    auto_target = []\n",
    "    for i in range(0, my_number_curves):\n",
    "        auto_target.append(target[i]-target_interp[i]+peq_build(freq, auto_peq))\n",
    "        \n",
    "    # greedy strategy: look for lowest & highest peak\n",
    "    sign, init_freq, init_freq_range = propose_range_freq(freq, auto_target[0])\n",
    "    init_dbGain_range = propose_range_dbGain(freq, auto_target[0], sign, init_freq)\n",
    "    init_Q_range = propose_range_Q()\n",
    "    biquad_range = propose_range_biquad()\n",
    "    \n",
    "    state, current_type, current_freq, current_Q, current_dbGain, current_loss = \\\n",
    "        find_best_biquad_differential_evolution(auto_target, init_freq_range, init_Q_range, init_dbGain_range, biquad_range, optim_iter)\n",
    "    if state:\n",
    "        biquad = (1.0, Biquad(current_type, current_freq, 48000, current_Q, current_dbGain))\n",
    "        auto_peq.append(biquad)\n",
    "        fixed_freq.add((sign, current_freq))\n",
    "        best_loss = current_loss\n",
    "        pref_score = score_loss(df_speaker, auto_peq)\n",
    "        logger.info('Iter {:2d} Optim converged loss {:2.2f} pref score {:2.2f} biquad {:1d} F:{:5.0f}Hz Q:{:2.2f} G:{:+2.2f}dB'.format(\n",
    "             optim_iter, best_loss, pref_score, current_type, current_freq, current_Q, current_dbGain))\n",
    "    else:\n",
    "        logger.error('Skip failed optim for best {} current'.format(best_loss, current_loss))\n",
    "        break\n",
    "\n",
    "auto_target = []\n",
    "for i in range(0, my_number_curves):\n",
    "    auto_target.append(target[i]-target_interp[i]+peq_build(freq, auto_peq))\n",
    "logger.info('OPTIM END: best loss {} with {} PEQs'.format(lw_loss(auto_target, []), len(auto_peq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log results        \n",
    "print('Manual QE')\n",
    "peq_print(manual_peq)\n",
    "\n",
    "score = scores(df_speaker)\n",
    "spin_manual, pir_manual, score_manual = scores_apply_filter(df_speaker, manual_peq)\n",
    "spin_auto, pir_auto, score_auto = scores_apply_filter(df_speaker, auto_peq)\n",
    "\n",
    "scores_print(score, score_manual)\n",
    "scores_print(score, score_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq = pd.DataFrame({'Freq': freq})\n",
    "for i, (pos, eq) in enumerate(manual_peq):\n",
    "    df_eq['EQ {}'.format(i)] = peq_build(freq, [(pos, eq)])\n",
    "    \n",
    "g_eq = alt.Chart(\n",
    "    graph_melt(df_eq)).mark_line().encode(\n",
    "    alt.X('Freq:Q', title='Freq (Hz)', scale=alt.Scale(type='log', nice=False, domain=[my_freq_reg_min, 20000])),\n",
    "    alt.Y('dB:Q', title='Sound Pressure (dB)', scale=alt.Scale(zero=False, domain=[-12,12 ])),\n",
    "    alt.Color('Measurements', type='nominal', sort=None),\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title='{} manual EQ'.format(speaker_name)\n",
    ")\n",
    "\n",
    "df_auto = pd.DataFrame({'Freq': freq})\n",
    "for i, (pos, eq) in enumerate(auto_peq):\n",
    "    df_auto['EQ {}'.format(i)] = peq_build(freq, [(pos, eq)])\n",
    "    \n",
    "g_auto = alt.Chart(\n",
    "    graph_melt(df_auto)).mark_line().encode(\n",
    "    alt.X('Freq:Q', title='Freq (Hz)', scale=alt.Scale(type='log', nice=False, domain=[my_freq_reg_min, 20000])),\n",
    "    alt.Y('dB:Q', title='Sound Pressure (dB)', scale=alt.Scale(zero=False, domain=[-12,12 ])),\n",
    "    alt.Color('Measurements', type='nominal', sort=None),\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title='{} auto EQ'.format(speaker_name)\n",
    ")\n",
    "\n",
    "g_eq_full = alt.Chart(\n",
    "    graph_melt(\n",
    "        pd.DataFrame({\n",
    "            'Freq': freq,\n",
    "            'Manual': peq_build(freq, manual_peq),\n",
    "            'Auto': peq_build(freq, auto_peq),\n",
    "        }))).mark_line().encode(\n",
    "    alt.X('Freq:Q', title='Freq (Hz)', scale=alt.Scale(type='log', nice=False, domain=[my_freq_reg_min, 20000])),\n",
    "    alt.Y('dB:Q', title='Sound Pressure (dB)', scale=alt.Scale(zero=False, domain=[-5,5 ])),\n",
    "    alt.Color('Measurements', type='nominal', sort=None),\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title='{} manual and auto filter'.format(speaker_name)\n",
    ")\n",
    "\n",
    "g_optim = alt.Chart(\n",
    "    graph_melt(\n",
    "        pd.DataFrame({\n",
    "            'Freq': freq,\n",
    "            #'LW-Reg': lw-lw_interp,\n",
    "            'Manual': lw_eq[0]-lw_eq_interp[0],\n",
    "            'Auto': target[0]-target_interp[0]+peq_build(freq, auto_peq),\n",
    "        }))).mark_line().encode(\n",
    "    alt.X('Freq:Q', title='Freq (Hz)', scale=alt.Scale(type='log', nice=False, domain=[my_freq_reg_min, 20000])),\n",
    "    alt.Y('dB:Q', title='Sound Pressure (dB)', scale=alt.Scale(zero=False, domain=[-5,5 ])),\n",
    "    alt.Color('Measurements', type='nominal', sort=None),\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title='{} manual and auto corrected {}'.format(speaker_name, curve_name[0])\n",
    ")\n",
    "\n",
    "((g_eq | g_auto) & (g_eq_full | g_optim)).resolve_scale('independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = target[0][0]\n",
    "alt.Chart(\n",
    "    graph_melt(\n",
    "        pd.DataFrame({\n",
    "            'Freq': freq,\n",
    "            'lw': target[0]-zero,\n",
    "            'lw interp': target_interp[0]-zero,\n",
    "            'manual': lw_eq[0]-lw_eq[0][0]-4,\n",
    "            'manual interp': lw_eq_interp[0]-lw_eq[0][0]-4,\n",
    "            'auto': target[0]-zero+peq_build(freq, auto_peq)-8,\n",
    "            'auto interp': target_interp[0]-zero-8,\n",
    "        }))\n",
    ").mark_line(\n",
    "    size=3\n",
    ").encode(\n",
    "    alt.X('Freq:Q', title='Freq (Hz)', scale=alt.Scale(type='log', nice=False, domain=[my_freq_reg_min, 20000])),\n",
    "    alt.Y('dB:Q', title='Sound Pressure (dB)', scale=alt.Scale(zero=False, domain=[-20, 0])),\n",
    "    alt.Color('Measurements', type='nominal', sort=None),\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title=speaker_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_params = {'xmin': 20, 'xmax': 20000, 'ymin': -50, 'ymax': 10, 'width': 400, 'height': 250}\n",
    "\n",
    "g_params['ymin'] = -40\n",
    "g_params['width'] = 800\n",
    "g_params['height'] = 400\n",
    "graph_spinorama(df_speaker['CEA2034'], g_params).properties(title='{} from ASR'.format(speaker_name)) | \\\n",
    "graph_spinorama(spin_manual, g_params).properties(title='{} ASR + manual EQ'.format(speaker_name)) | \\\n",
    "graph_spinorama(spin_auto, g_params).properties(title='{} ASR + auto EQ'.format(speaker_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_curve='Listening Window'\n",
    "# which_curve='Sound Power'\n",
    "which_curve='Estimated In-Room Response'\n",
    "data = df_speaker['CEA2034']\n",
    "data_manual = spin_manual\n",
    "data_auto = spin_auto\n",
    "if which_curve == 'Estimated In-Room Response':\n",
    "    data = df_speaker['Estimated In-Room Response']\n",
    "    data_auto = pir_auto\n",
    "    data_manual = pir_manual\n",
    "reg = graph_regression(data_auto.loc[(data_auto.Measurements==which_curve)], my_freq_reg_min, 20000)\n",
    "origin = (graph_freq(data.loc[(data.Measurements==which_curve)], g_params)+reg).properties(title='{} from ASR [{}]'.format(speaker_name, which_curve))\n",
    "manual = (graph_freq(data_manual.loc[(data_manual.Measurements==which_curve)], g_params)+reg).properties(title='{} from ASR [{}] + manual EQ'.format(speaker_name, which_curve))\n",
    "auto = (graph_freq(data_auto.loc[(data_auto.Measurements==which_curve)], g_params)+reg).properties(title='{} from ASR [{}] + auto EQ'.format(speaker_name, which_curve))\n",
    "(origin | manual | auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
