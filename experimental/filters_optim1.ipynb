{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sig\n",
    "from scipy.stats import linregress\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import scipy.optimize as opt\n",
    "import altair as alt\n",
    "import flammkuchen as fl\n",
    "from ray import tune\n",
    "from ray.tune import ProgressReporter, JupyterNotebookReporter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler, PopulationBasedTraining\n",
    "\n",
    "import sys, os, os.path\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"../src\"))\n",
    "\n",
    "from spinorama.filter_iir import Biquad\n",
    "from spinorama.filter_peq import peq_build, peq_print\n",
    "from spinorama.load import graph_melt\n",
    "from spinorama.load_rewseq import parse_eq_iir_rews\n",
    "from spinorama.graph import (\n",
    "    graph_spinorama,\n",
    "    graph_freq,\n",
    "    graph_regression_graph,\n",
    "    graph_regression,\n",
    ")\n",
    "from spinorama.compute_scores import scores\n",
    "from spinorama.filter_scores import scores_apply_filter, scores_print, scores_loss\n",
    "\n",
    "logger = logging.getLogger(\"spinorama\")\n",
    "fh = logging.FileHandler(\"debug_optim.log\")\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_speakers = fl.load(\"../cache.parse_all_speakers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norm\n",
    "def lw_loss1(local_target, peq):\n",
    "    return np.linalg.norm(local_target + peq_build(freq, peq), 2)\n",
    "\n",
    "\n",
    "# sum of L2 norms if we have multiple targets\n",
    "def lw_loss(local_target, peq):\n",
    "    return np.sum([lw_loss1(local_target[i], peq) for i in range(0, len(local_target))])\n",
    "\n",
    "\n",
    "# pref score\n",
    "# def lw_loss(local_target, peq):\n",
    "#    # WARNING df_speaker is global\n",
    "#    _, _, score = scores_apply_filter(df_speaker, peq)\n",
    "#    return -score['pref_score']\n",
    "\n",
    "# make LW as close as target as possible and SP flat\n",
    "# def lw_loss(local_target, peq):\n",
    "#    # want lw as close as possible from target\n",
    "#    lw = lw_loss1(local_target[0], peq)\n",
    "#    # want sound power to be flat but not necessary aligned with target\n",
    "#    slope, intercept, r_value, p_value, std_err = linregress(np.log10(freq), local_target[1])\n",
    "#    sp = 1.0-r_value**2\n",
    "#    return lw*sp\n",
    "\n",
    "\n",
    "# compute pref scrore\n",
    "def score_loss(df_spin, peq):\n",
    "    \"\"\"Compute the preference score for speaker\n",
    "\n",
    "    local_target: unsued\n",
    "    peq: evaluated peq\n",
    "\n",
    "    return minus score (we want to maximise the score)\n",
    "    \"\"\"\n",
    "    _, _, score = scores_apply_filter(df_spin, peq)\n",
    "    return -score[\"pref_score\"]\n",
    "\n",
    "\n",
    "# def lw_loss_r2(local_target, peq):\n",
    "#   _, _, r_value, _, _ = linregress(np.log(freq), local_target+peq_build(freq, peq))\n",
    "#   return -r_value**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of speaker\n",
    "# speaker_name = 'KEF LS50'\n",
    "speaker_name = \"KRK Systems Classic 5\"\n",
    "# speaker_name = 'Genelec 8341A'\n",
    "# all graphs for this speaker\n",
    "df_speaker = df_all_speakers[speaker_name][\"ASR\"][\"asr\"]\n",
    "# print(df_speaker.keys())\n",
    "# original_mean = df_speaker['CEA2034_original_mean']\n",
    "# read EQ for this speaker\n",
    "my_fs = 48000\n",
    "my_freq_reg_min = 300\n",
    "my_freq_mean_min = 100\n",
    "my_freq_mean_max = 300\n",
    "manual_peq = parse_eq_iir_rews(\"../datas/eq/{}/iir.txt\".format(speaker_name), my_fs)\n",
    "# peq_print(manual_peq)\n",
    "# curve to optimise for\n",
    "# curve_name = 'On Axis'\n",
    "# curve_name = ['Listening Window', 'Sound Power']\n",
    "# curve_name = ['On Axis', 'Sound Power']\n",
    "curve_name = [\"Listening Window\"]\n",
    "# curve_name = ['Estimated In-Room Response']\n",
    "# curve_name = ['Early Reflections']\n",
    "# curve_name = ['Sound Power']\n",
    "my_number_curves = len(curve_name)\n",
    "\n",
    "\n",
    "def getFreq(df_speaker_data):\n",
    "    # extract LW\n",
    "    columns = {\"Freq\"}.union(curve_name)\n",
    "    df = df_speaker_data[\"CEA2034_unmelted\"].loc[:, columns]\n",
    "    # selector\n",
    "    selector = df[\"Freq\"] > my_freq_reg_min\n",
    "    # freq\n",
    "    freq = df.loc[selector, \"Freq\"].values\n",
    "    local_target = []\n",
    "    for i in range(0, my_number_curves):\n",
    "        local_target.append(df.loc[selector, curve_name[i]].values)\n",
    "    return df, freq, local_target\n",
    "\n",
    "\n",
    "def getCurve(df, freq, current_curve_name):\n",
    "    selector = (df[\"Freq\"] > my_freq_mean_min) & (df[\"Freq\"] <= my_freq_mean_max)\n",
    "    # freq\n",
    "    current_curve = df.loc[df[\"Freq\"] > my_freq_reg_min, current_curve_name].values\n",
    "    # print(len(freq), len(current_curve))\n",
    "    # compute linear reg on lw\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(np.log10(freq), current_curve)\n",
    "    # normalise to have a flat target (primarly for bright speakers)\n",
    "    if current_curve_name in (\"Listening Window\", \"On Axis\"):\n",
    "        # freq_100_300 = df.loc[selector, 'Freq'].values\n",
    "        # lw_100_300 = df.loc[selector, current_curve_name].values\n",
    "        # lw_100_300_mean = np.mean(lw_100_300)\n",
    "        # print('Mean {} Intercept {}'.format(lw_100_300_mean, intercept))\n",
    "        # slope = (lw_100_300_mean-intercept)/(4+math.log10(2))\n",
    "        intercept = current_curve[0]\n",
    "        # if hot optimise for flat\n",
    "        if slope > 0:\n",
    "            slope = 0\n",
    "        # slighlithy downward\n",
    "        # slope = -2/math.log(20000)\n",
    "    target_interp = [(slope * math.log10(freq[i]) + intercept) for i in range(0, len(freq))]\n",
    "    print(\n",
    "        \"Slope {} Intercept {} R {} P {} err {}\".format(slope, intercept, r_value, p_value, std_err)\n",
    "    )\n",
    "    return target_interp\n",
    "\n",
    "\n",
    "# compute linear reg on lw filtered\n",
    "df, freq, target = getFreq(df_all_speakers[speaker_name][\"ASR\"][\"asr\"])\n",
    "target_interp = []\n",
    "for i in range(0, my_number_curves):\n",
    "    target_interp.append(getCurve(df, freq, curve_name[i]))\n",
    "\n",
    "# lw_interp_last = lw_interp[-1]-np.mean(lw_interp)\n",
    "# if lw_interp[-1]-np.mean(lw_interp)>0.3:\n",
    "#    print('Warning: bright target {}dB at {} Hz'.format(lw_interp_last, freq[-1]))\n",
    "\n",
    "df_eq, freq_eq, lw_eq = getFreq(df_all_speakers[speaker_name][\"ASR\"][\"asr_eq\"])\n",
    "lw_eq_interp = []\n",
    "lw_target = []\n",
    "for i in range(0, my_number_curves):\n",
    "    lw_eq_interp.append(getCurve(df_eq, freq_eq, curve_name[i]))\n",
    "    lw_target.append(lw_eq[i] - lw_eq_interp[i])\n",
    "\n",
    "print(\"manual eq loss: {}\".format(lw_loss(lw_target, [])))\n",
    "\n",
    "target_init = target[0][0]\n",
    "df_init_curve = pd.DataFrame(\n",
    "    {\n",
    "        \"Freq\": freq,\n",
    "        \"curve0\": target[0] - target_init,\n",
    "        \"curve0 interp\": target_interp[0] - target_init,\n",
    "        \"manual0\": lw_eq[0] - lw_eq[0][0] - 5,\n",
    "        \"manual0 interp\": lw_eq_interp[0] - lw_eq[0][0] - 5,\n",
    "    }\n",
    ")\n",
    "for i in range(1, len(curve_name)):\n",
    "    df_init_curve[\"curve{}\".format(i)] = target[i] - target[i][0] - (5 + i * 10)\n",
    "    df_init_curve[\"curve{} interp\".format(i)] = (\n",
    "        target_interp[i] - target_interp[i][0] - (5 + i * 10)\n",
    "    )\n",
    "    df_init_curve[\"manual{}\".format(i)] = lw_eq[i] - lw_eq[i][0] - ((i + 1) * 10)\n",
    "    df_init_curve[\"manual{} interp\".format(i)] = (\n",
    "        lw_eq_interp[i] - lw_eq_interp[i][0] - ((i + 1) * 10)\n",
    "    )\n",
    "\n",
    "alt.Chart(graph_melt(df_init_curve)).mark_line(size=3).encode(\n",
    "    alt.X(\n",
    "        \"Freq:Q\",\n",
    "        title=\"Freq (Hz)\",\n",
    "        scale=alt.Scale(type=\"log\", nice=False, domain=[my_freq_reg_min, 20000]),\n",
    "    ),\n",
    "    alt.Y(\n",
    "        \"dB:Q\",\n",
    "        title=\"Sound Pressure (dB)\",\n",
    "        scale=alt.Scale(zero=False, domain=[-40, 5]),\n",
    "    ),\n",
    "    alt.Color(\"Measurements\", type=\"nominal\", sort=None),\n",
    ").properties(width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(\"INFO\")\n",
    "smoke_test = False\n",
    "\n",
    "MAX_NUMBER_PEQ = 20\n",
    "MAX_STEPS_FREQ = 5\n",
    "MAX_STEPS_DBGAIN = 5\n",
    "MAX_STEPS_Q = 5\n",
    "MIN_DBGAIN = 0.5\n",
    "MAX_DBGAIN = 12\n",
    "MIN_Q = 1\n",
    "MAX_Q = 12\n",
    "\n",
    "if smoke_test:\n",
    "    MAX_NUMBER_PEQ = 3\n",
    "    MAX_STEPS_FREQ = 3\n",
    "    MAX_STEPS_DBGAIN = 3\n",
    "    MAX_STEPS_Q = 3\n",
    "\n",
    "# main peq that we want to find\n",
    "auto_peq = []\n",
    "# current target is delta between curve and a line\n",
    "auto_target = []\n",
    "for i in range(0, my_number_curves):\n",
    "    auto_target.append(target[i] - target_interp[i])\n",
    "\n",
    "fixed_freq = set()\n",
    "best_loss = lw_loss(auto_target, auto_peq)\n",
    "\n",
    "\n",
    "logger.info(\n",
    "    \"OPTIM {} START #PEQ {} Freq #{} Gain #{} +/-[{}, {}] Q #{} [{}, {}] Initial loss {}\".format(\n",
    "        curve_name,\n",
    "        MAX_NUMBER_PEQ,\n",
    "        MAX_STEPS_FREQ,\n",
    "        MAX_STEPS_DBGAIN,\n",
    "        MIN_DBGAIN,\n",
    "        MAX_DBGAIN,\n",
    "        MAX_STEPS_Q,\n",
    "        MIN_Q,\n",
    "        MAX_Q,\n",
    "        best_loss,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def find_largest_area(freq, curve):\n",
    "    def largest_area(positive_curve):\n",
    "        found_peaks, _ = sig.find_peaks(positive_curve, distance=10)\n",
    "        if len(found_peaks) == 0:\n",
    "            return None, None\n",
    "        # print('found peaks at {}'.format(found_peaks))\n",
    "        found_widths = sig.peak_widths(positive_curve, found_peaks, rel_height=0.1)[0]\n",
    "        # print('computed width at {}'.format(found_widths))\n",
    "        areas = [\n",
    "            (i, positive_curve[found_peaks[i]] * found_widths[i])\n",
    "            for i in range(0, len(found_peaks))\n",
    "        ]\n",
    "        # areas = [(i, positive_curve[found_peaks[i]]) for i in range(0, len(found_peaks))]\n",
    "        # print('areas {}'.format(areas))\n",
    "        sorted_areas = sorted(areas, key=lambda a: -a[1])\n",
    "        # rint('sorted {}'.format(sorted_areas))\n",
    "        ipeaks, area = sorted_areas[0]\n",
    "        return found_peaks[ipeaks], area\n",
    "\n",
    "    plus_curve = np.clip(curve, a_min=0, a_max=None)\n",
    "    plus_index, plus_areas = largest_area(plus_curve)\n",
    "    minus_curve = -np.clip(curve, a_min=None, a_max=0)\n",
    "    minus_index, minus_areas = largest_area(minus_curve)\n",
    "\n",
    "    if minus_areas is None:\n",
    "        return +1, plus_index, freq[plus_index]\n",
    "\n",
    "    if plus_areas is None:\n",
    "        return -1, minus_index, freq[minus_index]\n",
    "\n",
    "    if minus_areas > plus_areas:\n",
    "        return -1, minus_index, freq[minus_index]\n",
    "    else:\n",
    "        return +1, plus_index, freq[plus_index]\n",
    "\n",
    "\n",
    "def propose_range_freq(freq, local_target):\n",
    "    sign, indice, init_freq = find_largest_area(freq, local_target)\n",
    "    init_freq_min = max(init_freq * 0.9, 20)\n",
    "    init_freq_max = min(init_freq * 1.1, 20000)\n",
    "    init_freq_range = np.linspace(init_freq_min, init_freq_max, MAX_STEPS_FREQ).tolist()\n",
    "    if MAX_STEPS_FREQ == 1:\n",
    "        init_freq_range = [init_freq]\n",
    "    init_freq_range = np.linspace(init_freq_min, init_freq_max, MAX_STEPS_FREQ).tolist()\n",
    "    logger.debug(\"freq min {}Hz peak {}Hz max {}Hz\".format(init_freq_min, init_freq, init_freq_max))\n",
    "    return sign, init_freq, init_freq_range\n",
    "\n",
    "\n",
    "def propose_range_dbGain(freq, local_target, sign, init_freq):\n",
    "    spline = InterpolatedUnivariateSpline(np.log10(freq), local_target, k=1)\n",
    "    init_dbGain = abs(spline(np.log10(init_freq)))\n",
    "    init_dbGain_min = max(init_dbGain / 5, MIN_DBGAIN)\n",
    "    init_dbGain_max = min(init_dbGain * 5, MAX_DBGAIN)\n",
    "    init_dbGain_range = ()\n",
    "    if sign < 0:\n",
    "        init_dbGain_range = np.linspace(init_dbGain_min, init_dbGain_max, MAX_STEPS_DBGAIN).tolist()\n",
    "    else:\n",
    "        init_dbGain_range = np.linspace(\n",
    "            -init_dbGain_max, -init_dbGain_min, MAX_STEPS_DBGAIN\n",
    "        ).tolist()\n",
    "    logger.debug(\n",
    "        \"gain min {}dB peak {}dB max {}dB\".format(init_dbGain_min, init_dbGain, init_dbGain_max)\n",
    "    )\n",
    "    return init_dbGain_range\n",
    "\n",
    "\n",
    "def propose_range_Q():\n",
    "    return np.concatenate(\n",
    "        (\n",
    "            np.linspace(MIN_Q, 1, MAX_STEPS_Q),\n",
    "            np.linspace(1 + MIN_Q, MAX_Q, MAX_STEPS_Q),\n",
    "        ),\n",
    "        axis=0,\n",
    "    ).tolist()\n",
    "\n",
    "\n",
    "def propose_range_biquad():\n",
    "    return [\n",
    "        Biquad.PEAK\n",
    "    ]  # , Biquad.NOTCH] #, Biquad.LOWPASS, Biquad.HIGHPASS, Biquad.BANDPASS, Biquad.LOWSHELF, Biquad.HIGHSHELF]\n",
    "\n",
    "\n",
    "def find_best_biquad_raytune(auto_target, freq_range, Q_range, dbGain_range, biquad_range):\n",
    "    def lw_optimizer(config, checkpoint_dir=None):\n",
    "        peq = [\n",
    "            (\n",
    "                1.0,\n",
    "                Biquad(\n",
    "                    config[\"1_type\"],\n",
    "                    config[\"1_freq\"],\n",
    "                    48000,\n",
    "                    config[\"1_Q\"],\n",
    "                    config[\"1_dbGain\"],\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "        intermediate_score = lw_loss(auto_target, peq)\n",
    "        logger.debug(\"lw_optim: {} {}\".format(intermediate_score, peq_print(peq)))\n",
    "        tune.report(mean_loss=intermediate_score)\n",
    "\n",
    "    lw_analysis = tune.run(\n",
    "        lw_optimizer,\n",
    "        config={\n",
    "            \"1_freq\": tune.grid_search(freq_range),\n",
    "            \"1_Q\": tune.grid_search(Q_range),\n",
    "            \"1_dbGain\": tune.grid_search(dbGain_range),\n",
    "            \"1_type\": tune.grid_search(biquad_range),\n",
    "        },\n",
    "        progress_reporter=JupyterNotebookReporter(\n",
    "            overwrite=True,\n",
    "            max_progress_rows=5,\n",
    "            max_report_frequency=30,\n",
    "            print_intermediate_tables=False,\n",
    "        ),\n",
    "        resources_per_trial={\"cpu\": 1},\n",
    "        metric=\"mean_loss\",\n",
    "        mode=\"max\",\n",
    "    )\n",
    "\n",
    "    best = lw_analysis.get_best_trial(metric=\"mean_loss\", mode=\"min\").last_result\n",
    "    logger.debug(\"best {}\".format(best))\n",
    "    best_type = best[\"config\"][\"1_type\"]\n",
    "    best_dbGain = best[\"config\"][\"1_dbGain\"]\n",
    "    best_freq = best[\"config\"][\"1_freq\"]\n",
    "    best_Q = best[\"config\"][\"1_Q\"]\n",
    "    best_loss = best[\"mean_loss\"]\n",
    "\n",
    "    return True, best_type, best_freq, best_Q, best_dbGain, best_loss\n",
    "\n",
    "\n",
    "def find_best_biquad_shgo(auto_target, freq_range, Q_range, dbGain_range, biquad_range):\n",
    "    bT = 3\n",
    "\n",
    "    def opt_peq(x):\n",
    "        peq = [(1.0, Biquad(bT, x[0], 48000, x[1], x[2]))]\n",
    "        return lw_loss(auto_target, peq)\n",
    "\n",
    "    bounds = [\n",
    "        (freq_range[0], freq_range[-1]),\n",
    "        (Q_range[0], Q_range[-1]),\n",
    "        (dbGain_range[0], dbGain_range[-1]),\n",
    "    ]\n",
    "\n",
    "    logger.debug(\n",
    "        \"Optim (shgo): range is [{}, {}], [{}, {}], [{}, {}]\".format(\n",
    "            bounds[0][0],\n",
    "            bounds[0][1],\n",
    "            bounds[1][0],\n",
    "            bounds[1][1],\n",
    "            bounds[2][0],\n",
    "            bounds[2][1],\n",
    "        )\n",
    "    )\n",
    "    res = opt.shgo(opt_peq, bounds)\n",
    "    logger.info(\n",
    "        \"          shgo optim loss {:2.2f} in {} iter at F {:.0f} Hz Q {:2.2f}\".format(\n",
    "            res.fun, res.nfev, res.x[0], res.x[1], res.x[2]\n",
    "        )\n",
    "    )\n",
    "    return True, bT, res.x[0], res.x[1], res.x[2], res.fun\n",
    "\n",
    "\n",
    "for optim_iter in range(0, MAX_NUMBER_PEQ):\n",
    "    # target curve is currently a line between my_freq_reg_min Hz and 20kHz\n",
    "    # we are optimizing above my_freq_reg_min hz on anechoic data\n",
    "    auto_target = []\n",
    "    for i in range(0, my_number_curves):\n",
    "        auto_target.append(target[i] - target_interp[i] + peq_build(freq, auto_peq))\n",
    "\n",
    "    # current loss\n",
    "    # best_loss = lw_loss(auto_target, auto_peq)\n",
    "\n",
    "    # greedy strategy: look for lowest & highest peak\n",
    "    sign, init_freq, init_freq_range = propose_range_freq(freq, auto_target[0])\n",
    "    init_dbGain_range = propose_range_dbGain(freq, auto_target[0], sign, init_freq)\n",
    "    init_Q_range = propose_range_Q()\n",
    "    biquad_range = propose_range_biquad()\n",
    "\n",
    "    (\n",
    "        state,\n",
    "        current_type,\n",
    "        current_freq,\n",
    "        current_Q,\n",
    "        current_dbGain,\n",
    "        current_loss,\n",
    "    ) = find_best_biquad_raytune(\n",
    "        auto_target, init_freq_range, init_Q_range, init_dbGain_range, biquad_range\n",
    "    )\n",
    "    if state and current_loss < best_loss:\n",
    "        activate_local_optim = False\n",
    "        if activate_local_optim:\n",
    "            # can we optimise further with a local optimum?\n",
    "            elastic = 0.1\n",
    "            local_freq_range = [\n",
    "                max(current_freq * elastic, 300),\n",
    "                min(current_freq / elastic, 20000),\n",
    "            ]\n",
    "            local_dbGain_range = []\n",
    "            if current_dbGain > 0:\n",
    "                local_dbGain_range = [\n",
    "                    max(MIN_DBGAIN, current_dbGain * elastic),\n",
    "                    min(current_dbGain / elastic, MAX_DBGAIN),\n",
    "                ]\n",
    "            else:\n",
    "                local_dbGain_range = [\n",
    "                    max(-MAX_DBGAIN, current_dbGain / elastic),\n",
    "                    min(current_dbGain * elastic, -MIN_DBGAIN),\n",
    "                ]\n",
    "            local_Q_range = [\n",
    "                max(MIN_Q, current_Q * elastic),\n",
    "                min(current_Q / elastic, MAX_Q),\n",
    "            ]\n",
    "            (\n",
    "                state,\n",
    "                local_type,\n",
    "                local_freq,\n",
    "                local_Q,\n",
    "                local_dbGain,\n",
    "                local_loss,\n",
    "            ) = find_best_biquad_shgo(\n",
    "                auto_target,\n",
    "                local_freq_range,\n",
    "                local_Q_range,\n",
    "                local_dbGain_range,\n",
    "                biquad_range,\n",
    "            )\n",
    "            if state and (local_loss < current_loss):\n",
    "                logger.debug(\n",
    "                    \"Local optim loss {} current loss {} prev loss {}\".format(\n",
    "                        local_loss, current_loss, best_loss\n",
    "                    )\n",
    "                )\n",
    "                current_type = local_type\n",
    "                current_freq = local_freq\n",
    "                current_dbGain = local_dbGain\n",
    "                current_Q = local_Q\n",
    "                current_loss = local_loss\n",
    "            else:\n",
    "                logger.debug(\"Local optim failed\")\n",
    "        biquad = (\n",
    "            1.0,\n",
    "            Biquad(current_type, current_freq, 48000, current_Q, current_dbGain),\n",
    "        )\n",
    "        auto_peq.append(biquad)\n",
    "        fixed_freq.add((sign, current_freq))\n",
    "        best_loss = current_loss\n",
    "        pref_score = score_loss(df_speaker, auto_peq)\n",
    "        logger.info(\n",
    "            \"Iter {:2d} Optim converged loss {:2.2f} pref score {:2.2f} biquad {:1d} F:{:5.0f}Hz Q:{:2.2f} G:{:+2.2f}dB\".format(\n",
    "                optim_iter,\n",
    "                best_loss,\n",
    "                pref_score,\n",
    "                current_type,\n",
    "                current_freq,\n",
    "                current_Q,\n",
    "                current_dbGain,\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        logger.error(\"Skip failed optim for best {} current\".format(best_loss, current_loss))\n",
    "        break\n",
    "\n",
    "auto_target = []\n",
    "for i in range(0, my_number_curves):\n",
    "    auto_target.append(target[i] - target_interp[i] + peq_build(freq, auto_peq))\n",
    "logger.info(\"OPTIM END: best loss {} with {} PEQs\".format(lw_loss(auto_target, []), len(auto_peq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log results\n",
    "print(\"Manual QE\")\n",
    "peq_print(manual_peq)\n",
    "\n",
    "score = scores(df_speaker)\n",
    "spin_manual, pir_manual, score_manual = scores_apply_filter(df_speaker, manual_peq)\n",
    "spin_auto, pir_auto, score_auto = scores_apply_filter(df_speaker, auto_peq)\n",
    "\n",
    "scores_print(score, score_manual)\n",
    "scores_print(score, score_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq = pd.DataFrame({\"Freq\": freq})\n",
    "for i, (pos, eq) in enumerate(manual_peq):\n",
    "    df_eq[\"EQ {}\".format(i)] = peq_build(freq, [(pos, eq)])\n",
    "\n",
    "g_eq = (\n",
    "    alt.Chart(graph_melt(df_eq))\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\n",
    "            \"Freq:Q\",\n",
    "            title=\"Freq (Hz)\",\n",
    "            scale=alt.Scale(type=\"log\", nice=False, domain=[my_freq_reg_min, 20000]),\n",
    "        ),\n",
    "        alt.Y(\n",
    "            \"dB:Q\",\n",
    "            title=\"Sound Pressure (dB)\",\n",
    "            scale=alt.Scale(zero=False, domain=[-12, 12]),\n",
    "        ),\n",
    "        alt.Color(\"Measurements\", type=\"nominal\", sort=None),\n",
    "    )\n",
    "    .properties(width=800, height=400)\n",
    ")\n",
    "\n",
    "df_auto = pd.DataFrame({\"Freq\": freq})\n",
    "for i, (pos, eq) in enumerate(auto_peq):\n",
    "    df_auto[\"EQ {}\".format(i)] = peq_build(freq, [(pos, eq)])\n",
    "\n",
    "g_auto = (\n",
    "    alt.Chart(graph_melt(df_auto))\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\n",
    "            \"Freq:Q\",\n",
    "            title=\"Freq (Hz)\",\n",
    "            scale=alt.Scale(type=\"log\", nice=False, domain=[my_freq_reg_min, 20000]),\n",
    "        ),\n",
    "        alt.Y(\n",
    "            \"dB:Q\",\n",
    "            title=\"Sound Pressure (dB)\",\n",
    "            scale=alt.Scale(zero=False, domain=[-12, 12]),\n",
    "        ),\n",
    "        alt.Color(\"Measurements\", type=\"nominal\", sort=None),\n",
    "    )\n",
    "    .properties(width=800, height=400)\n",
    ")\n",
    "\n",
    "g_eq_full = (\n",
    "    alt.Chart(\n",
    "        graph_melt(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Freq\": freq,\n",
    "                    \"Manual\": peq_build(freq, manual_peq),\n",
    "                    \"Auto\": peq_build(freq, auto_peq),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\n",
    "            \"Freq:Q\",\n",
    "            title=\"Freq (Hz)\",\n",
    "            scale=alt.Scale(type=\"log\", nice=False, domain=[my_freq_reg_min, 20000]),\n",
    "        ),\n",
    "        alt.Y(\n",
    "            \"dB:Q\",\n",
    "            title=\"Sound Pressure (dB)\",\n",
    "            scale=alt.Scale(zero=False, domain=[-5, 5]),\n",
    "        ),\n",
    "        alt.Color(\"Measurements\", type=\"nominal\", sort=None),\n",
    "    )\n",
    "    .properties(width=800, height=400)\n",
    ")\n",
    "\n",
    "g_optim = (\n",
    "    alt.Chart(\n",
    "        graph_melt(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Freq\": freq,\n",
    "                    #'LW-Reg': lw-lw_interp,\n",
    "                    \"Manual\": lw_eq[0] - lw_eq_interp[0],\n",
    "                    \"Auto\": target[0] - target_interp[0] + peq_build(freq, auto_peq),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\n",
    "            \"Freq:Q\",\n",
    "            title=\"Freq (Hz)\",\n",
    "            scale=alt.Scale(type=\"log\", nice=False, domain=[my_freq_reg_min, 20000]),\n",
    "        ),\n",
    "        alt.Y(\n",
    "            \"dB:Q\",\n",
    "            title=\"Sound Pressure (dB)\",\n",
    "            scale=alt.Scale(zero=False, domain=[-5, 5]),\n",
    "        ),\n",
    "        alt.Color(\"Measurements\", type=\"nominal\", sort=None),\n",
    "    )\n",
    "    .properties(width=800, height=400)\n",
    ")\n",
    "\n",
    "((g_eq | g_auto) & (g_eq_full | g_optim)).resolve_scale(\"independent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = target[0][0]\n",
    "alt.Chart(\n",
    "    graph_melt(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Freq\": freq,\n",
    "                \"lw\": target[0] - zero,\n",
    "                \"lw interp\": target_interp[0] - zero,\n",
    "                \"manual\": lw_eq[0] - lw_eq[0][0] - 4,\n",
    "                \"manual interp\": lw_eq_interp[0] - lw_eq[0][0] - 4,\n",
    "                \"auto\": target[0] - zero + peq_build(freq, auto_peq) - 8,\n",
    "                \"auto interp\": target_interp[0] - zero - 8,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ").mark_line(size=3).encode(\n",
    "    alt.X(\n",
    "        \"Freq:Q\",\n",
    "        title=\"Freq (Hz)\",\n",
    "        scale=alt.Scale(type=\"log\", nice=False, domain=[my_freq_reg_min, 20000]),\n",
    "    ),\n",
    "    alt.Y(\n",
    "        \"dB:Q\",\n",
    "        title=\"Sound Pressure (dB)\",\n",
    "        scale=alt.Scale(zero=False, domain=[-20, 0]),\n",
    "    ),\n",
    "    alt.Color(\"Measurements\", type=\"nominal\", sort=None),\n",
    ").properties(\n",
    "    width=800, height=400, title=speaker_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_params = {\n",
    "    \"xmin\": 20,\n",
    "    \"xmax\": 20000,\n",
    "    \"ymin\": -50,\n",
    "    \"ymax\": 10,\n",
    "    \"width\": 400,\n",
    "    \"height\": 250,\n",
    "}\n",
    "\n",
    "g_params[\"ymin\"] = -40\n",
    "g_params[\"width\"] = 800\n",
    "g_params[\"height\"] = 400\n",
    "graph_spinorama(df_speaker[\"CEA2034\"], g_params).properties(\n",
    "    title=\"{} from ASR\".format(speaker_name)\n",
    ") | graph_spinorama(spin_manual, g_params).properties(title=\"ASR + manual EQ\") | graph_spinorama(\n",
    "    spin_auto, g_params\n",
    ").properties(\n",
    "    title=\"ASR + auto EQ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_curve='Listening Window'\n",
    "which_curve = \"Sound Power\"\n",
    "reg = graph_regression(\n",
    "    df_speaker[\"CEA2034\"].loc[(df_speaker[\"CEA2034\"].Measurements == which_curve)],\n",
    "    my_freq_reg_min,\n",
    "    20000,\n",
    ")\n",
    "origin = (\n",
    "    graph_freq(\n",
    "        df_speaker[\"CEA2034\"].loc[(df_speaker[\"CEA2034\"].Measurements == which_curve)],\n",
    "        g_params,\n",
    "    )\n",
    "    + reg\n",
    ").properties(title=\"{} from ASR [{}]\".format(speaker_name, which_curve))\n",
    "manual = (\n",
    "    graph_freq(spin_manual.loc[(spin_manual.Measurements == which_curve)], g_params) + reg\n",
    ").properties(title=\"ASR [{}] + manual EQ\".format(which_curve))\n",
    "auto = (\n",
    "    graph_freq(spin_auto.loc[(spin_auto.Measurements == which_curve)], g_params) + reg\n",
    ").properties(title=\"ASR [{}] + auto EQ\".format(which_curve))\n",
    "(origin | manual | auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
